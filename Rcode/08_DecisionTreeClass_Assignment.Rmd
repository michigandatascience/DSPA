---
title: "Data Science and Predictive Analytics (UMich HS650)"
subtitle: "<h2><u>Assignment 8: Decision Tree Divide and Conquer Classification</u></h2>"
author: "<h3>SOCR/MIDAS (Ivo Dinov)</h3>"
date: "`r format(Sys.time(), '%B %Y')`"
tags: [DSPA, SOCR, MIDAS, Big Dta, Predictive Analytics] 
output:
  html_document:
    theme: spacelab
    highlight: tango
    includes:
      before_body: SOCR_header.html
      after_body: SOCR_footer_tracker.html
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Explain the following concepts

* Information Gain Measure
* Impurity
* Entropy
* Gini

# Decision Tree Partitioning
Use the [SOCR Neonatal Pain data](http://wiki.socr.umich.edu/index.php/SOCR_Data_NIPS_InfantVitK_ShotData) to build and display a decision tree recursively partitioning the data using the provided features and attributes to split the data into clusters.

* Create two classes using variable Cluster
* Create random training and test datasets
* Train a decision tree model on the data, use `C5.0` and `rpart`, separately
* Evaluate the model performance and compare the `C5.0` and `rpart` results
* Tune the parameter for `rpart` and evaluate again
* Make predictions on testing data and assess the prediction accuracy - report the confusion matrix
* Comment on the classification performance
* Try to apply Random Forest classification and report the variables importance plot, predictions on testing data, and assess the prediction accuracy.