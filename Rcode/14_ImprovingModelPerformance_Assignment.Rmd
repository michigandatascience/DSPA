---
title: "Data Science and Predictive Analytics (UMich HS650)"
subtitle: "<h2><u>Assessment: 14. Improving Model Performance</u></h2>"
author: "<h3>SOCR/MIDAS (Ivo Dinov)</h3>"
date: "`r format(Sys.time(), '%B %Y')`"
tags: [DSPA, SOCR, MIDAS, Big Dta, Predictive Analytics] 
output:
  html_document:
    theme: spacelab
    highlight: tango
    includes:
      before_body: SOCR_header.html
      after_body: SOCR_footer_tracker.html
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Assessing Model Performance

Use some of the methods below to do classification, prediction, and model performance evaluation.

**Model**                   | **Learning Task**   | **Method** | **Parameters**
------------------------|-----------------|--------|----------------
KNN	|Classification|	`knn`|	`k`
Naïve Bayes|	Classification|	`nb`|	`fL, usekernel`
Decision Trees|	Classification|	`C5.0`|	`model, trials, winnow`
OneR Rule Learner|	Classification|	`OneR`|	None
RIPPER Rule Learner|	Classification|	`JRip`|	`NumOpt`
Linear Regression|	Regression|	`lm`|	None
Regression Trees|	Regression|	`rpart`|	`cp`
Model Trees|	Regression|	`M5`|	`pruned, smoothed, rules`
Neural Networks|	Dual use|	`nnet`|	`size, decay`
Support Vector Machines (Linear Kernel)|	Dual use|	`svmLinear`|	`C`
Support Vector Machines (Radial Basis Kernel)|	Dual use|	`svmRadial`|	`C, sigma`
Random Forests|	Dual use|	`rf`|	`mtry`

$$\textbf{Summary of some machine-learning classification technqiues.}$$

## Model improvement case study

From the [course datasets](https://umich.instructure.com/courses/38100/files/folder/data), use the [05_PPMI_top_UPDRS_Integrated_LongFormat1.csv](https://umich.instructure.com/files/330397/download?download_frd=1) case-study to perform a multi-class prediction. Use `ResearchGroup` as an outcome response, which includes three classes: "PD","Control" and "SWEDD" .

* Delete the ID column, impute the missing values using feature mean or median (justify your choice)
* Normalize the covariates
* Implement automated parameter tuning process and report the optimal accuracy and $\kappa$
* Set arguments and rerun the tuning - try different `method` and `number` settings
* Train a random forest classifier and tune the parameters, report the result and the cross table
* Use a bagging algorithm and report the accuracy and $\kappa$
* Perform a random Forest classification and report the accuracy and $\kappa$
* Report the accuracy of AdaBoost
* Finally, give a brief summary about all the model improvement approaches.

Try the procedure on other data in the list of [Case-Studies](https://umich.instructure.com/courses/38100/files/), e.g., [Traumatic Brain Injury Study](https://umich.instructure.com/files/416268/download?download_frd=1) and the corresponding [dataset](https://umich.instructure.com/files/416270/download?download_frd=1).